{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    import pickle\n",
    "    with open(filename, 'rb') as fp:\n",
    "        banana = pickle.load(fp)\n",
    "    return banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(signals, mfcconly=False):\n",
    "    X = []\n",
    "    y = []\n",
    "    for element in signals:\n",
    "        if mfcconly:\n",
    "            X.append(element[\"mfccs\"])\n",
    "        else:\n",
    "            X.append(np.concatenate((element[\"mfccs\"], element[\"delta\"], element[\"delta2\"])).T)\n",
    "        y.append(element[\"encodedLabel\"])\n",
    "    return np.array(X), np.array(y)\n",
    "        \n",
    "\n",
    "def get_data_splits(signals, test_size = 0.1, validation_size = 0.2, mfcconly=False):\n",
    "    X,y = getXy(signals, mfcconly)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "    \n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://miro.medium.com/max/486/1*jgWOhDiGjVp-NCSPa5abmg.png)\n",
    "\n",
    "L2 - Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model(input_shape, learning_rate, num_speakers, error=\"sparse_categorical_crossentropy\"):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    #convolution layer 1\n",
    "    model.add(keras.layers.Conv2D(64, (3,3), activation=\"relu\", input_shape=input_shape, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"))\n",
    "    \n",
    "    #clayer 2\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"))\n",
    "    \n",
    "    #clayer 3\n",
    "    model.add(keras.layers.Conv2D(32, (2,2), activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((2,2), strides=(2,2), padding=\"same\"))\n",
    "    \n",
    "    #flatten -> feed to dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    #softmax\n",
    "    model.add(keras.layers.Dense(num_speakers, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss=error, metrics=[\"accuracy\"])\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global vars\n",
    "LR = 0.0001\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=80\n",
    "\n",
    "#load data from pickles\n",
    "librosa_signals = unpickle(\"librosa_signals.pickle\")\n",
    "labelEncoder = unpickle(\"labelEncoder.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 232, 39, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 230, 37, 64)       640       \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 230, 37, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 115, 19, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 113, 17, 32)       18464     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 113, 17, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 57, 9, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 56, 8, 32)         4128      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 56, 8, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 28, 4, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 3584)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                229440    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 253,899\n",
      "Trainable params: 253,643\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 257ms/step - loss: 3.8656 - accuracy: 0.0875 - val_loss: 6.0568 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 1s 253ms/step - loss: 2.8425 - accuracy: 0.1250 - val_loss: 4.6070 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 2.3575 - accuracy: 0.2375 - val_loss: 3.9426 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1.8436 - accuracy: 0.4125 - val_loss: 3.5697 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 1.7411 - accuracy: 0.4375 - val_loss: 3.2980 - val_accuracy: 0.1000\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 1.6064 - accuracy: 0.4750 - val_loss: 3.1004 - val_accuracy: 0.1000\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 1.4789 - accuracy: 0.5750 - val_loss: 2.9619 - val_accuracy: 0.1000\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 1.3025 - accuracy: 0.6625 - val_loss: 2.8329 - val_accuracy: 0.1000\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 1.3252 - accuracy: 0.6125 - val_loss: 2.7028 - val_accuracy: 0.1000\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 1.2139 - accuracy: 0.6375 - val_loss: 2.5897 - val_accuracy: 0.1500\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 1.0636 - accuracy: 0.7375 - val_loss: 2.5128 - val_accuracy: 0.1500\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.9910 - accuracy: 0.7875 - val_loss: 2.4816 - val_accuracy: 0.2500\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.9142 - accuracy: 0.8000 - val_loss: 2.4450 - val_accuracy: 0.2500\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.8741 - accuracy: 0.8125 - val_loss: 2.4012 - val_accuracy: 0.2500\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.7681 - accuracy: 0.8250 - val_loss: 2.3523 - val_accuracy: 0.2500\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.7154 - accuracy: 0.8875 - val_loss: 2.2799 - val_accuracy: 0.3000\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.6253 - accuracy: 0.8375 - val_loss: 2.2080 - val_accuracy: 0.3000\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.5385 - accuracy: 0.9125 - val_loss: 2.1376 - val_accuracy: 0.3000\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.5523 - accuracy: 0.8625 - val_loss: 2.0828 - val_accuracy: 0.3000\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 0.6400 - accuracy: 0.8250 - val_loss: 2.0443 - val_accuracy: 0.3000\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.5909 - accuracy: 0.8750 - val_loss: 2.0268 - val_accuracy: 0.3000\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.4362 - accuracy: 0.9375 - val_loss: 1.9966 - val_accuracy: 0.3000\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.3389 - accuracy: 0.9625 - val_loss: 1.9649 - val_accuracy: 0.3000\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.3861 - accuracy: 0.9500 - val_loss: 1.9078 - val_accuracy: 0.3000\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.3768 - accuracy: 0.9750 - val_loss: 1.8421 - val_accuracy: 0.3000\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.3462 - accuracy: 0.9250 - val_loss: 1.7673 - val_accuracy: 0.5000\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.3531 - accuracy: 0.9625 - val_loss: 1.7289 - val_accuracy: 0.5500\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.3497 - accuracy: 0.9500 - val_loss: 1.6829 - val_accuracy: 0.5000\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.3055 - accuracy: 0.9375 - val_loss: 1.6518 - val_accuracy: 0.5500\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.3349 - accuracy: 0.9625 - val_loss: 1.6396 - val_accuracy: 0.6000\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.3662 - accuracy: 0.9375 - val_loss: 1.6392 - val_accuracy: 0.6000\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.2947 - accuracy: 0.9375 - val_loss: 1.6399 - val_accuracy: 0.6000\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.3420 - accuracy: 0.9125 - val_loss: 1.6193 - val_accuracy: 0.6000\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.2700 - accuracy: 0.9750 - val_loss: 1.5830 - val_accuracy: 0.6000\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 0.2412 - accuracy: 0.9625 - val_loss: 1.5450 - val_accuracy: 0.6000\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 1s 247ms/step - loss: 0.2035 - accuracy: 1.0000 - val_loss: 1.5024 - val_accuracy: 0.6500\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 0.2631 - accuracy: 0.9500 - val_loss: 1.4622 - val_accuracy: 0.7500\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 0.2613 - accuracy: 0.9625 - val_loss: 1.4282 - val_accuracy: 0.7500\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.2078 - accuracy: 0.9875 - val_loss: 1.3950 - val_accuracy: 0.7000\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.2233 - accuracy: 0.9750 - val_loss: 1.3686 - val_accuracy: 0.7500\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 0.1936 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.8000\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 0.2490 - accuracy: 0.9750 - val_loss: 1.3079 - val_accuracy: 0.8000\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.2107 - accuracy: 0.9750 - val_loss: 1.3018 - val_accuracy: 0.8000\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 0.1749 - accuracy: 0.9875 - val_loss: 1.2907 - val_accuracy: 0.7500\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.1996 - accuracy: 0.9625 - val_loss: 1.2708 - val_accuracy: 0.7500\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.1911 - accuracy: 0.9875 - val_loss: 1.2615 - val_accuracy: 0.7500\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.1815 - accuracy: 0.9875 - val_loss: 1.2517 - val_accuracy: 0.7500\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.1465 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.7500\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.1649 - accuracy: 0.9875 - val_loss: 1.1993 - val_accuracy: 0.7500\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.1655 - accuracy: 1.0000 - val_loss: 1.1620 - val_accuracy: 0.7500\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.1941 - accuracy: 0.9875 - val_loss: 1.1383 - val_accuracy: 0.7500\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.1880 - accuracy: 0.9750 - val_loss: 1.1293 - val_accuracy: 0.8000\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.1522 - accuracy: 0.9875 - val_loss: 1.1112 - val_accuracy: 0.8000\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.8000\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.1838 - accuracy: 0.9875 - val_loss: 1.0502 - val_accuracy: 0.8000\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 0.8000\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.8000\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.9282 - val_accuracy: 0.8000\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.1890 - accuracy: 0.9625 - val_loss: 0.9014 - val_accuracy: 0.8000\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.1560 - accuracy: 0.9875 - val_loss: 0.8764 - val_accuracy: 0.8000\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1456 - accuracy: 0.9875 - val_loss: 0.8467 - val_accuracy: 0.8000\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.1399 - accuracy: 0.9875 - val_loss: 0.8300 - val_accuracy: 0.8000\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.8000\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 0.1372 - accuracy: 0.9875 - val_loss: 0.8027 - val_accuracy: 0.8000\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 0.1645 - accuracy: 0.9875 - val_loss: 0.7758 - val_accuracy: 0.8500\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 0.7586 - val_accuracy: 0.8500\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.8500\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.8500\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1431 - accuracy: 0.9875 - val_loss: 0.7439 - val_accuracy: 0.8500\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 0.1516 - accuracy: 0.9875 - val_loss: 0.7375 - val_accuracy: 0.8500\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.8500\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.6699 - val_accuracy: 0.8500\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.1337 - accuracy: 0.9875 - val_loss: 0.6442 - val_accuracy: 0.9000\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.1171 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9500\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.1131 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 0.1253 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.1401 - accuracy: 0.9875 - val_loss: 0.5106 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4415 - accuracy: 0.9167\n",
      "Test error: 0.4414548873901367, test acc: 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = get_data_splits(librosa_signals, mfcconly=False)\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "\n",
    "model = build_tf_model(input_shape, LR, len(labelEncoder.classes_))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_validation,y_validation))\n",
    "\n",
    "test_err, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test error: {test_err}, test acc: {test_acc}\")\n",
    "\n",
    "# model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_librosa_91.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knn librosa\n",
    "\n",
    "generalnie chyba jest przetrenowany i musiałbym zrobić crossvalidation faktycznie\n",
    "\n",
    "każde moje nagranie stawia na Tobiasza XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from pickles\n",
    "librosa_signals = unpickle(\"librosa_signals.pickle\")\n",
    "labelEncoder = unpickle(\"labelEncoder.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_LENGTH = len(librosa_signals[0][\"signal\"]) #any signal from here, they were padded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpkData(signals):\n",
    "    X = []\n",
    "    speakerData = []\n",
    "    for element in signals:\n",
    "        trackEncodings = np.concatenate((element[\"mfccs\"], element[\"delta\"], element[\"delta2\"])).T\n",
    "        speakerData.append({\"speaker\": element[\"encodedLabel\"], \"data\": trackEncodings.flatten()})            \n",
    "    return speakerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkData = getSpkData(librosa_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(lambda entry: entry[\"data\"], spkData))\n",
    "y = list(map(lambda entry: entry[\"speaker\"],spkData))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782608695652174"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.66666667,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.predict_proba([X_test[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_pickle(filename, data):\n",
    "    import pickle\n",
    "    with open(filename+'.pickle', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "export_to_pickle(\"knn78.pickle\", neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(record_seconds  = 4):\n",
    "    import pyaudio\n",
    "    import wave\n",
    "\n",
    "    # the file name output you want to record into\n",
    "    filename = \"recorded.wav\"\n",
    "    # set the chunk size of 1024 samples\n",
    "    chunk = 1024\n",
    "    # sample format\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    # mono, change to 2 if you want stereo\n",
    "    channels = 1\n",
    "    # 44100 samples per second\n",
    "    sample_rate = 16000\n",
    "    record_seconds = record_seconds\n",
    "    # initialize PyAudio object\n",
    "    p = pyaudio.PyAudio()\n",
    "    # open stream object as input & output\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=channels,\n",
    "                    rate=sample_rate,\n",
    "                    input=True,\n",
    "                    output=True,\n",
    "                    frames_per_buffer=chunk)\n",
    "    frames = []\n",
    "    print(\"Recording...\")\n",
    "    for i in range(int(sample_rate / chunk * record_seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        # if you want to hear your voice while recording\n",
    "        # stream.write(data)\n",
    "        frames.append(data)\n",
    "    print(\"Finished recording.\")\n",
    "    # stop and close stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # terminate pyaudio object\n",
    "    p.terminate()\n",
    "    # save audio file\n",
    "    # open the file in 'write bytes' mode\n",
    "    wf = wave.open(filename, \"wb\")\n",
    "    # set the channels\n",
    "    wf.setnchannels(channels)\n",
    "    # set the sample format\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    # set the sample rate\n",
    "    wf.setframerate(sample_rate)\n",
    "    # write the frames as bytes\n",
    "    wf.writeframes(b\"\".join(frames))\n",
    "    # close the file\n",
    "    wf.close()\n",
    "    \n",
    "def trp(l, n): #trim or pad list l to be of n length\n",
    "    return l[:n] + [0]*(n-len(l))\n",
    "\n",
    "def librosaReadAudio(filename = \"recorded.wav\"):\n",
    "    import scipy\n",
    "    import librosa\n",
    "    signal, sampling_rate = librosa.load(filename, sr=None)\n",
    "    signal = trp(signal.tolist(), SIGNAL_LENGTH) \n",
    "    mfcc = librosa.feature.mfcc(y=np.array(signal), n_mfcc=13, sr = sampling_rate, window = scipy.signal.windows.hann, n_fft=2048, hop_length=512, win_length = None)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    data = np.concatenate((mfcc, delta, delta2)).T\n",
    "    return data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "#run and start talking\n",
    "record_audio(record_seconds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = librosaReadAudio(\"untitled.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AM</th>\n",
       "      <th>AP</th>\n",
       "      <th>AS</th>\n",
       "      <th>BG</th>\n",
       "      <th>CD</th>\n",
       "      <th>MJ</th>\n",
       "      <th>PP</th>\n",
       "      <th>TC</th>\n",
       "      <th>WK</th>\n",
       "      <th>WM</th>\n",
       "      <th>ZB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AM   AP   AS   BG   CD   MJ   PP   TC   WK   WM   ZB\n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(neigh.predict_proba([data]), columns=labelEncoder.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
