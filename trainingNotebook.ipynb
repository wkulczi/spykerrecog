{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    import pickle\n",
    "    with open(filename, 'rb') as fp:\n",
    "        banana = pickle.load(fp)\n",
    "    return banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(signals, mfcconly=False):\n",
    "    X = []\n",
    "    y = []\n",
    "    for element in signals:\n",
    "        if mfcconly:\n",
    "            X.append(element[\"mfccs\"])\n",
    "        else:\n",
    "            X.append(np.concatenate((element[\"mfccs\"], element[\"delta\"], element[\"delta2\"])).T)\n",
    "        y.append(element[\"encodedLabel\"])\n",
    "    return np.array(X), np.array(y)\n",
    "        \n",
    "\n",
    "def get_data_splits(signals, test_size = 0.1, validation_size = 0.2, mfcconly=False):\n",
    "    X,y = getXy(signals, mfcconly)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "    \n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://miro.medium.com/max/486/1*jgWOhDiGjVp-NCSPa5abmg.png)\n",
    "\n",
    "L2 - Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model(input_shape, learning_rate, num_speakers, error=\"sparse_categorical_crossentropy\"):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    #convolution layer 1\n",
    "    model.add(keras.layers.Conv2D(64, (3,3), activation=\"relu\", input_shape=input_shape, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"))\n",
    "    \n",
    "    #clayer 2\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"))\n",
    "    \n",
    "    #clayer 3\n",
    "    model.add(keras.layers.Conv2D(32, (2,2), activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((2,2), strides=(2,2), padding=\"same\"))\n",
    "    \n",
    "    #flatten -> feed to dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    #softmax\n",
    "    model.add(keras.layers.Dense(num_speakers, activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss=error, metrics=[\"accuracy\"])\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global vars\n",
    "LR = 0.0001\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=80\n",
    "\n",
    "#load data from pickles\n",
    "librosa_signals = unpickle(\"librosa_signals.pickle\")\n",
    "labelEncoder = unpickle(\"labelEncoder.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 232, 39, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 39, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = get_data_splits(librosa_signals, mfcconly=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 230, 37, 64)       640       \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 230, 37, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 115, 19, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 113, 17, 32)       18464     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 113, 17, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 57, 9, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 56, 8, 32)         4128      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 56, 8, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 28, 4, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 3584)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                229440    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 253,899\n",
      "Trainable params: 253,643\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 257ms/step - loss: 3.8656 - accuracy: 0.0875 - val_loss: 6.0568 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 1s 253ms/step - loss: 2.8425 - accuracy: 0.1250 - val_loss: 4.6070 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 2.3575 - accuracy: 0.2375 - val_loss: 3.9426 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1.8436 - accuracy: 0.4125 - val_loss: 3.5697 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 1.7411 - accuracy: 0.4375 - val_loss: 3.2980 - val_accuracy: 0.1000\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 1.6064 - accuracy: 0.4750 - val_loss: 3.1004 - val_accuracy: 0.1000\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 1.4789 - accuracy: 0.5750 - val_loss: 2.9619 - val_accuracy: 0.1000\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 1.3025 - accuracy: 0.6625 - val_loss: 2.8329 - val_accuracy: 0.1000\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 1.3252 - accuracy: 0.6125 - val_loss: 2.7028 - val_accuracy: 0.1000\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 1.2139 - accuracy: 0.6375 - val_loss: 2.5897 - val_accuracy: 0.1500\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 1.0636 - accuracy: 0.7375 - val_loss: 2.5128 - val_accuracy: 0.1500\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.9910 - accuracy: 0.7875 - val_loss: 2.4816 - val_accuracy: 0.2500\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.9142 - accuracy: 0.8000 - val_loss: 2.4450 - val_accuracy: 0.2500\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.8741 - accuracy: 0.8125 - val_loss: 2.4012 - val_accuracy: 0.2500\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.7681 - accuracy: 0.8250 - val_loss: 2.3523 - val_accuracy: 0.2500\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.7154 - accuracy: 0.8875 - val_loss: 2.2799 - val_accuracy: 0.3000\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.6253 - accuracy: 0.8375 - val_loss: 2.2080 - val_accuracy: 0.3000\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.5385 - accuracy: 0.9125 - val_loss: 2.1376 - val_accuracy: 0.3000\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.5523 - accuracy: 0.8625 - val_loss: 2.0828 - val_accuracy: 0.3000\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 0.6400 - accuracy: 0.8250 - val_loss: 2.0443 - val_accuracy: 0.3000\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.5909 - accuracy: 0.8750 - val_loss: 2.0268 - val_accuracy: 0.3000\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.4362 - accuracy: 0.9375 - val_loss: 1.9966 - val_accuracy: 0.3000\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.3389 - accuracy: 0.9625 - val_loss: 1.9649 - val_accuracy: 0.3000\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.3861 - accuracy: 0.9500 - val_loss: 1.9078 - val_accuracy: 0.3000\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.3768 - accuracy: 0.9750 - val_loss: 1.8421 - val_accuracy: 0.3000\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.3462 - accuracy: 0.9250 - val_loss: 1.7673 - val_accuracy: 0.5000\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.3531 - accuracy: 0.9625 - val_loss: 1.7289 - val_accuracy: 0.5500\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.3497 - accuracy: 0.9500 - val_loss: 1.6829 - val_accuracy: 0.5000\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.3055 - accuracy: 0.9375 - val_loss: 1.6518 - val_accuracy: 0.5500\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.3349 - accuracy: 0.9625 - val_loss: 1.6396 - val_accuracy: 0.6000\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.3662 - accuracy: 0.9375 - val_loss: 1.6392 - val_accuracy: 0.6000\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.2947 - accuracy: 0.9375 - val_loss: 1.6399 - val_accuracy: 0.6000\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.3420 - accuracy: 0.9125 - val_loss: 1.6193 - val_accuracy: 0.6000\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.2700 - accuracy: 0.9750 - val_loss: 1.5830 - val_accuracy: 0.6000\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 0.2412 - accuracy: 0.9625 - val_loss: 1.5450 - val_accuracy: 0.6000\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 1s 247ms/step - loss: 0.2035 - accuracy: 1.0000 - val_loss: 1.5024 - val_accuracy: 0.6500\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 0.2631 - accuracy: 0.9500 - val_loss: 1.4622 - val_accuracy: 0.7500\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 0.2613 - accuracy: 0.9625 - val_loss: 1.4282 - val_accuracy: 0.7500\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.2078 - accuracy: 0.9875 - val_loss: 1.3950 - val_accuracy: 0.7000\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.2233 - accuracy: 0.9750 - val_loss: 1.3686 - val_accuracy: 0.7500\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 0.1936 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.8000\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 0.2490 - accuracy: 0.9750 - val_loss: 1.3079 - val_accuracy: 0.8000\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.2107 - accuracy: 0.9750 - val_loss: 1.3018 - val_accuracy: 0.8000\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 0.1749 - accuracy: 0.9875 - val_loss: 1.2907 - val_accuracy: 0.7500\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.1996 - accuracy: 0.9625 - val_loss: 1.2708 - val_accuracy: 0.7500\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.1911 - accuracy: 0.9875 - val_loss: 1.2615 - val_accuracy: 0.7500\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.1815 - accuracy: 0.9875 - val_loss: 1.2517 - val_accuracy: 0.7500\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.1465 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.7500\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.1649 - accuracy: 0.9875 - val_loss: 1.1993 - val_accuracy: 0.7500\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.1655 - accuracy: 1.0000 - val_loss: 1.1620 - val_accuracy: 0.7500\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.1941 - accuracy: 0.9875 - val_loss: 1.1383 - val_accuracy: 0.7500\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.1880 - accuracy: 0.9750 - val_loss: 1.1293 - val_accuracy: 0.8000\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.1522 - accuracy: 0.9875 - val_loss: 1.1112 - val_accuracy: 0.8000\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.8000\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.1838 - accuracy: 0.9875 - val_loss: 1.0502 - val_accuracy: 0.8000\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 0.8000\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.8000\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.9282 - val_accuracy: 0.8000\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.1890 - accuracy: 0.9625 - val_loss: 0.9014 - val_accuracy: 0.8000\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.1560 - accuracy: 0.9875 - val_loss: 0.8764 - val_accuracy: 0.8000\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1456 - accuracy: 0.9875 - val_loss: 0.8467 - val_accuracy: 0.8000\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.1399 - accuracy: 0.9875 - val_loss: 0.8300 - val_accuracy: 0.8000\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.8000\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 0.1372 - accuracy: 0.9875 - val_loss: 0.8027 - val_accuracy: 0.8000\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 0.1645 - accuracy: 0.9875 - val_loss: 0.7758 - val_accuracy: 0.8500\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 0.7586 - val_accuracy: 0.8500\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.8500\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.8500\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.1431 - accuracy: 0.9875 - val_loss: 0.7439 - val_accuracy: 0.8500\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 0.1516 - accuracy: 0.9875 - val_loss: 0.7375 - val_accuracy: 0.8500\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.8500\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.6699 - val_accuracy: 0.8500\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.1337 - accuracy: 0.9875 - val_loss: 0.6442 - val_accuracy: 0.9000\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.1171 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9500\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.1131 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 0.1253 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.1401 - accuracy: 0.9875 - val_loss: 0.5106 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4415 - accuracy: 0.9167\n",
      "Test error: 0.4414548873901367, test acc: 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = get_data_splits(librosa_signals, mfcconly=False)\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "\n",
    "model = build_tf_model(input_shape, LR, len(labelEncoder.classes_))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_validation,y_validation))\n",
    "\n",
    "test_err, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test error: {test_err}, test acc: {test_acc}\")\n",
    "\n",
    "# model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_librosa_91.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knn librosa\n",
    "\n",
    "generalnie chyba jest przetrenowany i musiałbym zrobić crossvalidation faktycznie\n",
    "\n",
    "każde moje nagranie stawia na Tobiasza XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from pickles\n",
    "librosa_signals = unpickle(\"librosa_signals.pickle\")\n",
    "labelEncoder = unpickle(\"labelEncoder.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_LENGTH = len(librosa_signals[0][\"signal\"]) #any signal from here, they were padded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpkData(signals):\n",
    "    X = []\n",
    "    speakerData = []\n",
    "    for element in signals:\n",
    "        trackEncodings = np.concatenate((element[\"mfccs\"], element[\"delta\"], element[\"delta2\"])).T\n",
    "        speakerData.append({\"speaker\": element[\"encodedLabel\"], \"data\": trackEncodings.flatten()})            \n",
    "    return speakerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkData = getSpkData(librosa_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(lambda entry: entry[\"data\"], spkData))\n",
    "y = list(map(lambda entry: entry[\"speaker\"],spkData))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9048"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9048"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695652173913043"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.66666667,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.predict_proba([X_test[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_pickle(filename, data):\n",
    "    import pickle\n",
    "    with open(filename+'.pickle', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "export_to_pickle(\"knn78.pickle\", neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectedResult = [d for d in exampleSet if d['type'] in keyValList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [np.concatenate((x['mfccs'], x['delta'], x['delta2'])).T for x in librosa_signals if x[\"encodedLabel\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_data = []\n",
    "for iter in range(len(labelEncoder.classes_)):\n",
    "    data = [(np.concatenate((x['mfccs'], x['delta'], x['delta2'])).T).flatten() for x in librosa_signals if  x[\"encodedLabel\"] == iter]\n",
    "    y = labelEncoder.classes_[iter]\n",
    "    speaker_data = {\"y\":y, \"x\": data}\n",
    "    speakers_data.append(speaker_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = speakers_data[0]['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-418.55934491,   47.74896254,   28.67844339, ...,    0.        ,\n",
       "          0.        ,    0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = np.vstack((a,speakers_data[0]['x'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-418.55934491,   47.74896254,   28.67844339, ...,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [-395.52408034,   53.52468454,   -0.99826231, ...,    0.        ,\n",
       "           0.        ,    0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speakers_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b84d4da1fcd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgmm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGaussianMixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeakers_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'speakers_data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm=GaussianMixture(n_components=8).fit(speakers_data[0]['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speakers_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92fe4ad55b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspeakerModels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mspeaker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspeakers_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mgmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mspeakerModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'speakers_data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "speakerModels = []\n",
    "for speaker in speakers_data:\n",
    "    gmm = GaussianMixture(n_components = 4).fit(speaker['x'])\n",
    "    speakerModels.append({'y':speaker['y'], \"model\": gmm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.predict_proba([X_train[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
